"""
Category Embeddings - Pre-computed embeddings for semantic pre-filtering.

This module provides a singleton class for loading and using pre-computed
category embeddings to perform fast semantic similarity matching before
expensive LLM binary classification.

Uses JSON format for safe serialization (no pickle).

Usage:
    from components.labeling.category_embeddings import CategoryEmbeddings

    # Get singleton instance
    embeddings = CategoryEmbeddings.get_instance()

    # Compute similarities to a ticket embedding
    ticket_embedding = [...]  # 3072-dimensional vector
    similarities = embeddings.compute_similarities(ticket_embedding)
    # Returns: [(category_id, similarity_score), ...] sorted descending
"""

import json
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path

from config import Config


class CategoryEmbeddings:
    """
    Singleton cache for pre-computed category embeddings.

    Loads category embeddings from JSON file and provides methods for
    computing cosine similarity between a ticket and all categories.

    Embeddings are generated by combining each category's description
    and keywords into a single text, then embedding with text-embedding-3-large.
    """

    _instance: Optional["CategoryEmbeddings"] = None
    _embeddings: Dict[str, List[float]] = {}
    _metadata: Dict[str, Any] = {}
    _category_ids: List[str] = []
    _embedding_matrix: Optional[np.ndarray] = None

    def __new__(cls) -> "CategoryEmbeddings":
        """Ensure singleton pattern."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._load_embeddings()
        return cls._instance

    @classmethod
    def get_instance(cls) -> "CategoryEmbeddings":
        """Get singleton instance."""
        return cls()

    @classmethod
    def reset_instance(cls) -> None:
        """Reset singleton (useful for testing or reloading)."""
        cls._instance = None
        cls._embeddings = {}
        cls._metadata = {}
        cls._category_ids = []
        cls._embedding_matrix = None

    def _load_embeddings(self) -> None:
        """Load pre-computed embeddings from JSON file."""
        embeddings_path = Config.CATEGORY_EMBEDDINGS_PATH

        # Check if embeddings file exists
        if not embeddings_path.exists():
            print(f"   [CategoryEmbeddings] Embeddings not found: {embeddings_path}")
            print(f"   [CategoryEmbeddings] Run: python scripts/generate_category_embeddings.py")
            self._embeddings = {}
            self._category_ids = []
            return

        # Load embeddings from JSON (safe format)
        try:
            with open(embeddings_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            # Extract embeddings and metadata
            self._embeddings = data.get("embeddings", {})
            self._metadata = data.get("metadata", {})
            self._category_ids = list(self._embeddings.keys())

            if self._category_ids:
                # Build matrix for vectorized similarity computation
                self._embedding_matrix = np.array([
                    self._embeddings[cat_id] for cat_id in self._category_ids
                ])

                # L2 normalize embeddings for cosine similarity
                norms = np.linalg.norm(self._embedding_matrix, axis=1, keepdims=True)
                norms = np.where(norms > 0, norms, 1)  # Avoid division by zero
                self._embedding_matrix = self._embedding_matrix / norms

                print(f"   [CategoryEmbeddings] Loaded {len(self._category_ids)} category embeddings")
            else:
                print(f"   [CategoryEmbeddings] No embeddings found in file")

        except Exception as e:
            print(f"   [CategoryEmbeddings] Error loading embeddings: {e}")
            self._embeddings = {}
            self._category_ids = []

    def is_loaded(self) -> bool:
        """Check if embeddings are loaded."""
        return len(self._embeddings) > 0

    def get_embedding(self, category_id: str) -> Optional[List[float]]:
        """Get embedding for a specific category."""
        return self._embeddings.get(category_id)

    def get_category_ids(self) -> List[str]:
        """Get list of all category IDs with embeddings."""
        return self._category_ids

    def get_embedding_dimension(self) -> int:
        """Get embedding dimension."""
        if self._embeddings:
            return len(next(iter(self._embeddings.values())))
        return Config.EMBEDDING_DIMENSIONS

    def get_metadata(self) -> Dict[str, Any]:
        """Get embedding metadata."""
        return self._metadata

    def compute_similarities(
        self,
        ticket_embedding: List[float]
    ) -> List[Tuple[str, float]]:
        """
        Compute cosine similarity between ticket embedding and all categories.

        Args:
            ticket_embedding: List of floats (embedding_dim length)

        Returns:
            List of (category_id, similarity_score) tuples, sorted by score descending.
            Similarity scores are in range [-1, 1], with 1 being most similar.
        """
        if not self.is_loaded():
            print("   [CategoryEmbeddings] Warning: Embeddings not loaded")
            return []

        # Ensure input is numpy array
        ticket_vec = np.array(ticket_embedding)

        # L2 normalize ticket embedding
        norm = np.linalg.norm(ticket_vec)
        if norm > 0:
            ticket_vec = ticket_vec / norm

        # Compute cosine similarities (dot product of normalized vectors)
        similarities = self._embedding_matrix @ ticket_vec

        # Create (category_id, score) tuples
        results = [
            (self._category_ids[i], float(similarities[i]))
            for i in range(len(self._category_ids))
        ]

        # Sort by similarity descending
        results.sort(key=lambda x: x[1], reverse=True)

        return results

    def get_top_k_candidates(
        self,
        ticket_embedding: List[float],
        top_k: int = 5,
        threshold: float = 0.3
    ) -> List[Tuple[str, float]]:
        """
        Get top-K category candidates above similarity threshold.

        Args:
            ticket_embedding: List of floats (embedding_dim length)
            top_k: Maximum number of candidates to return
            threshold: Minimum similarity threshold

        Returns:
            List of (category_id, similarity_score) tuples for top candidates.
        """
        all_similarities = self.compute_similarities(ticket_embedding)

        # Filter by threshold and limit to top_k
        candidates = [
            (cat_id, score) for cat_id, score in all_similarities
            if score >= threshold
        ][:top_k]

        return candidates

    def __len__(self) -> int:
        """Return number of category embeddings."""
        return len(self._embeddings)
